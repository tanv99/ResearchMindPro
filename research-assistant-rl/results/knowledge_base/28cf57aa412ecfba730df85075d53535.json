{
  "title": "ImageNet classification with deep convolutional neural networks",
  "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
  "year": 2017,
  "citationCount": 75536,
  "authors": [
    {
      "name": "Alex Krizhevsky"
    },
    {
      "name": "Ilya Sutskever"
    },
    {
      "name": "Geoffrey E. Hinton"
    }
  ],
  "url": "https://openalex.org/W2163605009",
  "references": [
    "https://openalex.org/W2061212083",
    "https://openalex.org/W2911964244",
    "https://openalex.org/W2166049352",
    "https://openalex.org/W2101926813",
    "https://openalex.org/W2546302380",
    "https://openalex.org/W2015861736",
    "https://openalex.org/W2130325614",
    "https://openalex.org/W2018435387",
    "https://openalex.org/W2026942141",
    "https://openalex.org/W2144161366",
    "https://openalex.org/W2110764733",
    "https://openalex.org/W2053229256",
    "https://openalex.org/W2097117768",
    "https://openalex.org/W2169805405",
    "https://openalex.org/W2108598243",
    "https://openalex.org/W1665214252",
    "https://openalex.org/W2108069432",
    "https://openalex.org/W2156163116",
    "https://openalex.org/W3118608800",
    "https://openalex.org/W2154579312",
    "https://openalex.org/W1904365287",
    "https://openalex.org/W2097356275",
    "https://openalex.org/W2134557905",
    "https://openalex.org/W2396976214",
    "https://openalex.org/W1576445103",
    "https://openalex.org/W1499991161"
  ],
  "source": "openalex",
  "paper_id": "28cf57aa412ecfba730df85075d53535",
  "retrieved_by_query": "transformer attention mechanism"
}
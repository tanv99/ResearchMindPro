{
  "title": "Instant neural graphics primitives with a multiresolution hash encoding",
  "abstract": "Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920\u00d71080.",
  "year": 2022,
  "citationCount": 3089,
  "authors": [
    {
      "name": "Thomas M\u00fcller"
    },
    {
      "name": "Alex Evans"
    },
    {
      "name": "Christoph Schied"
    },
    {
      "name": "Alexander Keller"
    }
  ],
  "url": "https://openalex.org/W4221151978",
  "references": [
    "https://openalex.org/W6926412321",
    "https://openalex.org/W3095682719",
    "https://openalex.org/W3035507572",
    "https://openalex.org/W1971126479",
    "https://openalex.org/W4200391991",
    "https://openalex.org/W1489869152",
    "https://openalex.org/W2018890661",
    "https://openalex.org/W3035515538",
    "https://openalex.org/W3180799285",
    "https://openalex.org/W2964288609",
    "https://openalex.org/W3109585842",
    "https://openalex.org/W2979652999",
    "https://openalex.org/W3106552726",
    "https://openalex.org/W3176679482",
    "https://openalex.org/W2029315739",
    "https://openalex.org/W3187556994",
    "https://openalex.org/W3134621679",
    "https://openalex.org/W2071906076",
    "https://openalex.org/W2122676594",
    "https://openalex.org/W6605572670",
    "https://openalex.org/W3117476483",
    "https://openalex.org/W3184957317",
    "https://openalex.org/W2902563172",
    "https://openalex.org/W6607725495",
    "https://openalex.org/W1583837637",
    "https://openalex.org/W1564611446",
    "https://openalex.org/W3179416528",
    "https://openalex.org/W3185535223"
  ],
  "source": "openalex",
  "paper_id": "d136cee046f662cf458de6a68a91a41b",
  "retrieved_by_query": "transformer attention mechanism"
}